{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from pomegranate import *\n",
    "\n",
    "# get the path for the database\n",
    "database_path = \"database/name_origins.sqlite\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Database into a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start up a connection to the database\n",
    "engine = create_engine(f\"sqlite:///{database_path}\")\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the needed data from the database into dataframes\n",
    "name_df = pd.read_sql(\"SELECT * FROM name\", connection)\n",
    "\n",
    "# close the connection, because who needs to use SQLalchemy\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>gender</th>\n",
       "      <th>origin_id</th>\n",
       "      <th>meaning</th>\n",
       "      <th>used_in</th>\n",
       "      <th>additional_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Aaliyah</td>\n",
       "      <td>Girl</td>\n",
       "      <td>3</td>\n",
       "      <td>Lofty, sublime, exalted</td>\n",
       "      <td>Arabic and English speaking countries</td>\n",
       "      <td>This particular spelling of the name Aliyah is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>Boy</td>\n",
       "      <td>23</td>\n",
       "      <td>Mountain</td>\n",
       "      <td>English speaking countries</td>\n",
       "      <td>Anglicisation of the Hebrew Aharon.  In the Bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Abagail</td>\n",
       "      <td>Girl</td>\n",
       "      <td>23</td>\n",
       "      <td>Father in rejoicing</td>\n",
       "      <td>English speaking countries</td>\n",
       "      <td>A modern respelling of Abigail.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Abbey</td>\n",
       "      <td>Both</td>\n",
       "      <td>23</td>\n",
       "      <td>Father in rejoicing</td>\n",
       "      <td>English speaking countries</td>\n",
       "      <td>A nickname for Abigail, and also a surname fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Abbie</td>\n",
       "      <td>Girl</td>\n",
       "      <td>23</td>\n",
       "      <td>Father in rejoicing</td>\n",
       "      <td>English speaking countries</td>\n",
       "      <td>Nickname for Abigail.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    title gender  origin_id                  meaning  \\\n",
       "0   1  Aaliyah   Girl          3  Lofty, sublime, exalted   \n",
       "1   2    Aaron    Boy         23                 Mountain   \n",
       "2   3  Abagail   Girl         23      Father in rejoicing   \n",
       "3   4    Abbey   Both         23      Father in rejoicing   \n",
       "4   5    Abbie   Girl         23      Father in rejoicing   \n",
       "\n",
       "                                 used_in  \\\n",
       "0  Arabic and English speaking countries   \n",
       "1             English speaking countries   \n",
       "2             English speaking countries   \n",
       "3             English speaking countries   \n",
       "4             English speaking countries   \n",
       "\n",
       "                                     additional_info  \n",
       "0  This particular spelling of the name Aliyah is...  \n",
       "1  Anglicisation of the Hebrew Aharon.  In the Bi...  \n",
       "2                    A modern respelling of Abigail.  \n",
       "3  A nickname for Abigail, and also a surname fro...  \n",
       "4                              Nickname for Abigail.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove all of the fluff text from the used_in column\n",
    "name_usage_split_df = name_df\n",
    "name_usage_split_df['used_in'] = name_usage_split_df['used_in'].str.replace(' speaking countries', '')\n",
    "name_usage_split_df['used_in'] = name_usage_split_df['used_in'].str.replace(' and', '')\n",
    "name_usage_split_df['used_in'] = name_usage_split_df['used_in'].str.replace(',', '')\n",
    "\n",
    "# chekcout the colums to make sure things work right\n",
    "# pd.DataFrame(name_origin_split_df.groupby(by=\"used_in\").count()).reset_index()[\"used_in\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary to hold the names, organized by usage\n",
    "names_by_usage = {}\n",
    "\n",
    "# iterate through each row of the DF\n",
    "for i, row in name_usage_split_df.iterrows():\n",
    "    # pull out all of the origins from the DF row and put them into a list\n",
    "    usages = name_usage_split_df.loc[i, \"used_in\"].split(' ')\n",
    "    \n",
    "    # loop through all the list of origins to find matching keys (langueages that use the name)\n",
    "    for usage in usages:\n",
    "        # if it no keys match the existing keys add in a new one\n",
    "        if not (usage in names_by_usage.keys()):\n",
    "            names_by_usage[usage] = []\n",
    "        # then add the names to the apropreate usage keys\n",
    "        names_by_usage[usage].append(name_usage_split_df.loc[i, \"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Arabic', 'English', 'Spanish', 'Hebrew', 'Yiddish', 'African', 'Polish', 'French', 'Swahili', 'Hindi', 'Italian', 'Greek', 'German', 'Gaelic', 'Japanese', 'Hawaiian', 'Portuguese', 'Albanian', 'Russian', 'Slovak', 'Dutch', 'Hungarian', 'Czech', 'Romanian', 'Swedish', 'Armenian', 'Bulgarian', 'Croatian', 'Serbian', 'Danish', 'Norwegian', 'Finnish', 'Indonesian', 'Catalan', 'Estonian', 'Urdu', 'Welsh', 'Latvian', 'Lithuanian', 'Turkish', 'Persian', 'Chinese', 'Vietnamese', 'Icelandic', 'Ukrainian'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkout those keys\n",
    "names_by_usage.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Arabic', 'English', 'Spanish', 'Hebrew', 'Polish', 'French', 'Hindi', 'Italian', 'German', 'Portuguese', 'Dutch', 'Swedish'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete all usage categories that have less than 40 names,\n",
    "# otherwise usage categories will have improper sets\n",
    "for key in list(names_by_usage.keys()):\n",
    "    if len(names_by_usage[key]) < 40:\n",
    "        del names_by_usage[key]\n",
    "\n",
    "# check out the new list of languages that have more than 40 names (from the currrent data set at least)\n",
    "names_by_usage.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change all names to lowercase\n",
    "for key, names in names_by_usage.items():\n",
    "    for i, name in enumerate(names):\n",
    "        names_by_usage[key][i] = name.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aaliyah', 'abdul', 'abdullah', 'aisha', 'ali', 'alia', 'aliyah', 'aman', 'amani', 'amina', 'amir', 'amira', 'amirah', 'anwar', 'ayesha', 'bilal', 'diya', 'farrah', 'fatima', 'hamza', 'hana', 'hassan', 'ibrahim', 'jahir', 'jamal', 'jamil', 'jamila', 'jessenia', 'jiya', 'kadijah', 'kamila', 'khadijah', 'khalil', 'latifah', 'leila', 'leyla', 'lina', 'malik', 'malika', 'mariam', 'maryam', 'mira', 'mohamed', 'mohammad', 'mohammed', 'mona', 'muhammad', 'mustafa', 'nadia', 'naima', 'najee', 'nasir', 'omar', 'omari', 'raheem', 'rajan', 'rashaad', 'rasheed', 'rayan', 'salma', 'sameer', 'samir', 'samira', 'sanaa', 'saniya', 'shakira', 'taj', 'taja', 'tariq', 'xerxes', 'yasmin', 'zaid', 'zaida', 'zara']\n"
     ]
    }
   ],
   "source": [
    "# Check the names\n",
    "print(names_by_usage[\"Arabic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all fo the lists of names\n",
    "for key in names_by_usage.keys():\n",
    "    # for each list generate and fit a model\n",
    "    model = MarkovChain.from_samples(names_by_usage[key], k=1)\n",
    "    model.fit(names_by_usage[key])\n",
    "    \n",
    "    # convert the model to a json\n",
    "    model_data = model.to_json()\n",
    "    \n",
    "    # save the json to a file\n",
    "    with open(f\"models/{key}.json\", 'w') as outfile:\n",
    "        json.dump(model_data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open json containing the model\n",
    "with open(\"models/Arabic.json\", 'r') as infile:\n",
    "    same_data = json.load(infile)\n",
    "\n",
    "# Load the json into a model\n",
    "new_model = MarkovChain.from_json(same_data)\n",
    "\n",
    "# Get a sample of the model for texting\n",
    "new_model.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_markov_chain(name_list):\n",
    "    letter_occurance = {}\n",
    "    markov_chain = {}\n",
    "\n",
    "    for name in name_list:\n",
    "        for i, char in enumerate(name):\n",
    "            if i >= 1:\n",
    "                element = f\"{name[i-1]}{name[i]}\"\n",
    "                if element in letter_occurance:\n",
    "                    letter_occurance[element] += 1\n",
    "                else:\n",
    "                    letter_occurance[element] = 1\n",
    "\n",
    "    total_cases = 0\n",
    "\n",
    "    for element in letter_occurance.values():\n",
    "        total_cases += element\n",
    "\n",
    "    for key, value in letter_occurance.items():\n",
    "        markov_chain[key] = round(value/total_cases*100, 2)\n",
    "        \n",
    "    return markov_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = get_markov_chain(names_by_usage['Arabic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.9099999999999\n"
     ]
    }
   ],
   "source": [
    "test = 0\n",
    "for sample in test_sample.values():\n",
    "    test += sample\n",
    "    \n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
